{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d593fd4-5dd1-4ac7-ab72-98b4d5743e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "import spacy\n",
    "from tabulate import tabulate\n",
    "nlp_id = spacy.blank('id')\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117a480-cd88-4cde-9903-81c6e19732a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/News.csv\")\n",
    "df.isnull().sum()\n",
    "# Dropping the rows having None values\n",
    "df = df.dropna(subset=['content'])\n",
    "# Resetting the indices\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de8cb0-751a-40d5-87f7-d995e2bef7bc",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0abac6c-f4ed-426b-831e-927e384cd3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_stem(token_DocID):\n",
    "    new_token = []\n",
    "    for to_ in token_DocID:\n",
    "        new_token.append( ( stemmer.stem(to_) ))\n",
    "    return new_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f2941-6c1c-41ea-80ec-547d81d77c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_tokenization(contents):\n",
    "    list_tokens_from_docs = []\n",
    "    for content in contents:\n",
    "        nlp_contents = nlp_id(content.lower())\n",
    "        clean_token = []\n",
    "        for token_of_nlp_contents in nlp_contents:\n",
    "            # remove punctuation & remove stopword\n",
    "            if not token_of_nlp_contents.is_digit and not token_of_nlp_contents.is_punct \\\n",
    "                and not token_of_nlp_contents.is_stop:\n",
    "                clean_token.append(token_of_nlp_contents)\n",
    "        list_tokens_from_docs.append(clean_token)\n",
    "    return list_tokens_from_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be5679-a3df-4caa-84a3-79f5eff467d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp_tokens = nlp_tokenization(df['content'])\n",
    "# Use only samples from the dataset to test the functionality of the code.\n",
    "nlp_stem = sentence_stem(df['content'][0:30])\n",
    "nlp_tokens = nlp_tokenization(nlp_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c9407d-6165-4a83-8734-1e19b6800f53",
   "metadata": {},
   "source": [
    "## Pairing Term and Document ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011c100-8e78-4235-8c69-ec2755bca1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_token_docID(nlp_tokens):\n",
    "    doc_list_ofToken_DocID = []\n",
    "    # index_docID\n",
    "    for docID, doc_list_T in enumerate(nlp_tokens):\n",
    "        for doc_list in doc_list_T:\n",
    "            doc_list_ofToken_DocID.append((doc_list.text, docID+1))\n",
    "    return doc_list_ofToken_DocID\n",
    "\n",
    "def remove_space(nlp_tokens_tup):\n",
    "    new_tokens = []\n",
    "    for i in nlp_tokens_tup:\n",
    "        if not i[0].isspace():\n",
    "            new_tokens.append(i)\n",
    "    return new_tokens\n",
    "\n",
    "def sort_token_docID(tup):\n",
    "    return(sorted(tup, key = lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c1662-c70c-469f-948d-18564737d37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp_tokens_docId = pair_token_docID(nlp_tokens)\n",
    "nlp_tokens_docId_clean_space = remove_space(nlp_tokens_docId)\n",
    "nlp_tokens_docId_sorted = sort_token_docID(nlp_tokens_docId_clean_space)\n",
    "nlp_tokens_docId_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4f0b1-6a7f-4494-ae8c-4b4e32e9b65b",
   "metadata": {},
   "source": [
    "## Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf0080-5a28-4054-911e-09a7700b516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a9b0f-7771-428f-9c4d-b944d7dc8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(tokens_docID):\n",
    "    vocab = {}\n",
    "    for token, docId in tokens_docID:\n",
    "        if not token in vocab:\n",
    "            vocab[token] = deque()\n",
    "            vocab[token].append(docId)\n",
    "        else:\n",
    "            temp_post_list = vocab[token]\n",
    "            temp_post_list.append(docId)\n",
    "            # prevent duplication\n",
    "            temp_post_list = sorted(set(temp_post_list))\n",
    "            # back to linkedlist\n",
    "            temp_post_list = deque(temp_post_list)\n",
    "            vocab[token] = temp_post_list\n",
    "    vocab_freq = {}\n",
    "    # pairing term and doc frequency\n",
    "    for key, val in vocab.items():\n",
    "        vocab_freq[(key, len(val))] = val\n",
    "    return vocab_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d9d6a-9879-4f6c-991a-36b8850d44ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_inverted_index = inverted_index(nlp_tokens_docId_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34d9e2-3ffc-4436-8629-828ed6642063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a99fc1-8e46-4ff4-b0bd-f6343b9ed03d",
   "metadata": {},
   "source": [
    "## Processing Boolean queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65320852-8f2c-451b-805f-e0fa42dd6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanQueries:\n",
    "    \n",
    "    def __init__(self, inverted_index, debug=False):\n",
    "        self.inverted_index = inverted_index\n",
    "        self.debug = debug\n",
    "        keys_of_inverted_index = self.inverted_index.keys()\n",
    "        self.keys_of_inverted_index = dict(keys_of_inverted_index)\n",
    "\n",
    "    def intersection_query(self, query1, query2):\n",
    "        # get doc frequency from query\n",
    "        doc_freq1 = self.keys_of_inverted_index[query1]\n",
    "        doc_freq2 = self.keys_of_inverted_index[query2]\n",
    "        # get posting list\n",
    "        pl_q1 = self.inverted_index[(query1, doc_freq1)]\n",
    "        pl_q2 = self.inverted_index[(query2, doc_freq2)]\n",
    "        answer = set(pl_q1) & set(pl_q2)\n",
    "        if self.debug:\n",
    "            data = [[pl_q1, pl_q2, answer]]\n",
    "            headers = [f\"posting list of {query1}\", f\"posting list of {query2}\", \"intersection result\"]\n",
    "            print(tabulate(data, headers=headers))\n",
    "        return answer\n",
    "    \n",
    "    def union_query(self, query1, query2):\n",
    "        # get doc frequency from query\n",
    "        doc_freq1 = self.keys_of_inverted_index[query1]\n",
    "        doc_freq2 = self.keys_of_inverted_index[query2]\n",
    "        # get posting list\n",
    "        pl_q1 = self.inverted_index[(query1, doc_freq1)]\n",
    "        pl_q2 = self.inverted_index[(query2, doc_freq2)]\n",
    "        answer = set(pl_q1) | set(pl_q2)\n",
    "        if self.debug:\n",
    "            data = [[pl_q1, pl_q2, answer]]\n",
    "            headers = [f\"posting list of {query1}\", f\"posting list of {query2}\", \"union result\"]\n",
    "            print(tabulate(data, headers=headers))\n",
    "        return answer\n",
    "    \n",
    "    def negation_query(self, query):\n",
    "        # get doc frequency from query\n",
    "        doc_freq = self.keys_of_inverted_index[query]\n",
    "        # get posting list\n",
    "        pl_q = self.inverted_index[(query, doc_freq)]\n",
    "        # get docID membership\n",
    "        self.docID_membership()\n",
    "        answer = set(self.docID_space) - set(pl_q)\n",
    "        if self.debug:\n",
    "            data = [[pl_q, self.docID_space , answer]]\n",
    "            headers = [f\"posting list of {query}\", \"docID membership\", \"negation result\"]\n",
    "            print(tabulate(data, headers=headers))\n",
    "        return answer\n",
    "    \n",
    "    def docID_membership(self):\n",
    "        docID_space = set()\n",
    "        for posting_lists in self.inverted_index.values():\n",
    "            for pl in posting_lists:\n",
    "                docID_space.add(pl)\n",
    "        self.docID_space = sorted(docID_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd4c30-f5f6-4b21-b6d1-0ce1a091f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample data from inverted index to test the query\n",
    "mock_inverted_index = {}\n",
    "num_mock = 20\n",
    "track_mock = 0\n",
    "for key, values in dict_inverted_index.items():\n",
    "    mock_inverted_index[key] = values\n",
    "    track_mock += 1\n",
    "    if track_mock == num_mock:\n",
    "        break\n",
    "mock_inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c99b11-c538-4d3c-979c-1352997f5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "booleanQuery = BooleanQueries(mock_inverted_index, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7960e-5e6a-4290-b423-8b36a47a7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "booleanQuery.intersection_query('agustus', 'air')\n",
    "print(\"\\n\")\n",
    "booleanQuery.union_query('agustus', 'air')\n",
    "print(\"\\n\")\n",
    "booleanQuery.negation_query('agustus')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
